
![[Screenshot 2024-11-27 162025.png]]

**全文主旨：**
# Materials and Methods
我们提出的模型会在图？中展示。...（总结图的信息）

## Dataset √
我们使用的数据集来自CDM，包含了834 circRNAs，138 diseases，and 555 miRNAs。目前已经发现存在关联的circRNA-disease associations有989对，837对miRNA-disease associations以及902对circRNA-miRNA interactions。（这些关联数据分别从？？？... 数据库中提取。）


---
## CircRNA-disease-miRNA heterogeneous graph √
- 建图角度
- R关联矩阵解释（inter层间）
- 为什么引入miRNA的缘由，要结合实际问题带出来，？？？证明了这个事
- S相似矩阵解释（intra层内）
- 相似性怎么算的？已有方法？（引用）？？？认为两个 circRNA (miRNA) 关联的疾病越多，这两个 lncRNA (miRNA) 越相似。简略描述方法。（审稿人需要才放上补充文件SF）
- 最后构建的图模型矩阵。（因为后面图Transformer用到了W，保留该段）


---
## RGTransformer
原始的图Transformer忽略了图的归纳偏差，特别是与结构相关的偏差，这对于图的任务尤其重要。尽管一些方式利用位置编码和注意力机制模拟归纳偏差，但他们的效果并不理想。
	图的归纳偏差（inductive bias）是指在图结构数据中，模型在学习和推理时所依赖的先验知识或假设。这些偏差通常与图的结构特征相关，例如节点之间的连接关系、节点的特征以及图的整体拓扑结构。归纳偏差帮助模型更好地理解和处理图数据，尤其是在图任务中，例如节点分类、链接预测等。
	在图神经网络（GTs）中，归纳偏差可以影响模型的性能，因为它们决定了模型如何利用图的结构信息来进行推理。如果模型未能有效地捕捉这些偏差，可能会导致性能下降。因此，研究者们尝试通过不同的方法（如位置编码和注意力偏差）来增强模型对图的归纳偏差的建模能力
**传统的自注意力机制在处理上，单纯使用图的特征矩阵来作为输入，往往无法充分利用图的拓扑信息系，尽管一些方法利用位置编码来弥补这部分的空缺，但是最终达到的效果不甚理想。我们需要一种方法来不仅关注到结构上的重要性，而且能够增强Transformer的注意力机制，关注重要的信息，减少聚合过程中的冗余。**
Transformer 在形成这些加权图（即注意力矩阵）时并不直接考虑输入结构（即现有边）。  因此，由于特征相似性，注意力机制可能会忽略某些相邻节点的重要性
### Restarted Random Walk-Based Structural Embeddings√
- 目的：充分利用异构图拓扑结构，辅助关联预测，提高模型表达能力。（我的模型所有结点都学了拓扑嵌入，结点周围结构）
- 游走策略：概率游走，restart。
- 嵌入意义：结点到其他结点的概率，一行嵌入和为1。

### Guiding Attention with Restarted Random Walk-Based Structural Embeddings
原因：随机游走是一种有效的图表示学习方法，它能够捕捉**结点之间的关系和结构信息**，并且通过引入“重启”的机制，可以更好地强调与目标结点更相近的结点，从而提高信息聚合的质量。因此，我们通过引入随机游走的结构嵌入，可以为注意力机制提供更丰富的上下文信息，使得模型在计算注意力分数的时候，能更好地关注结点之间的关系。
。。。
影响：通过引入随机游走的结构嵌入，使得自注意力机制能更好的利用图的结构信息，在图分类、结点分类、关系预测等任务中的效果尤为突出。该方法能够适应不同类型的图数据，尤其在结点数量较多或结构复杂的情况下，仍能保持较好的性能。

### Gating Enhance
原因：在深层网络中，**随着层数的增加，信息可能逐渐丢失或变得不稳定**，逐渐偏离原始的特征，为了**确保重要信息能够有效地在各层之间传递**，引入了门控机制。
目的：门控单元主要将当前层的原始输入和最终输出进行加权融合，这种融合能够结合当前层的提取的更高维特征与原始输入特征，使得模型在确保重要信息不严重丢失的情况下，能够挖掘更深层的信息，保证模型表达的稳定性。
影响：通过引入门控机制，能让Transformer更好的捕捉和利用输入数据的特征，并且能够保证模型的稳定性，降低模型对参数变化的敏感性；门控机制的引入，帮助模型更好地捕捉复杂结构和长距离依赖关系。


---
## Multi-view Pairwise features extraction based on CNN and KAN
卷积关注输入信息的局部特征（相邻特征之间的关系模式），特征聚合和降维，减少信息冗余。卷积核在特定区域滑动，捕捉的是结点特征的局部关系，收到感受野大小的限制。

### Convolutional Neural Network (CNN) Channel

### Kolmogorov-Arnold Network (KAN) Channel
双通道下的**KAN：**
1. **全局特征捕捉**：
    - KAN网络通过其可学习的激活函数和样条函数的灵活性，能够更好地捕捉全局特征和复杂的非线性关系。与卷积网络主要关注局部特征不同，KAN网络可以在更大范围内整合信息，从而识别出节点间的潜在关联。
2. **函数逼近能力**：
    - KAN网络基于Kolmogorov-Arnold表示定理，能够通过组合多个一维函数来逼近复杂的多维函数。这使得KAN网络能够有效地建模节点特征之间的复杂关系，进而帮助预测节点间的关联。
3. **可解释性**：
    - KAN网络的结构使得其决策过程更加可解释，用户可以直观地理解模型如何通过不同的特征组合来判断节点之间的关联。这对于科学研究和实际应用中理解模型的行为非常重要。
4. **互补性**：
    - 在双通道网络中，卷积网络和KAN网络的结合可以实现互补。卷积网络专注于局部特征的提取，而KAN网络则能够整合全局信息。通过这种方式，模型可以同时利用局部和全局特征，从而提高预测的准确性。

与MLP区别：
1. **激活函数的位置**：
    - KAN网络的激活函数是可学习的，并且被放置在边缘（权重）上。
    - MLP网络的激活函数是固定的，位于节点（神经元）上。
2. **权重的形式**：
    - KAN网络没有**线性权重**，所有的权重参数都被替换为参数化为样条函数的单变量函数。
    - MLP网络使用固定的线性权重。

优势：
1. **可学习的激活函数**：
    - KAN网络在边缘上使用可学习的激活函数，这使得网络能够自适应地调整其结构，以更好地拟合数据，从而提高准确性。
2. **参数化的样条函数**：
    - KAN网络使用样条函数来表示权重，这种灵活性允许模型捕捉复杂的非线性关系，进而提升模型在函数拟合任务中的表现。
3. **可视化和交互性**：
    - KAN网络的结构使得其计算过程更容易被可视化，用户可以直观地理解模型的决策过程。这种可解释性使得科学家和研究人员能够更好地与模型互动，从而发现和理解潜在的数学和物理规律。
4. **更少的参数需求**：
    - KAN网络通常能够以较少的参数达到与更大MLP网络相当或更好的准确性，这意味着在相对简单的模型中也能实现高效的学习。

为了有效地预测节点间的关联性，我们提出了一种双通道网络模型，该模型结合了卷积神经网络（CNN）和Kolmogorov-Arnold网络（KAN），以==充分利用局部和全局特征==。**传统的单一模型在处理复杂的图结构数据时常常面临局部特征与全局特征之间的权衡，导致信息的丢失和预测性能的降低**。因此，设计一个能够同时捕捉局部和全局信息的双通道模型是十分必要的。

#### 双通道设计

在本研究中，我们的双通道模型由两个主要部分组成：卷积网络通道和KAN网络通道。卷积网络通道专注于提取输入张量中的局部特征，利用卷积操作有效地捕捉相邻节点之间的关系。通过滑动窗口机制，卷积网络能够自动学习到节点特征的局部模式，这对于识别节点间的直接关联至关重要。

KAN网络通道旨在捕捉全局特征。KAN网络通过可学习的激活函数和样条函数，能够灵活地建模节点特征之间的复杂非线性关系。**与卷积网络的局部聚合不同，KAN网络能够整合全局信息，从而识别出节点之间潜在的长距离关联**。这种全局视角使得KAN网络在处理高维特征时表现出色，尤其是在节点特征之间存在复杂交互的情况下。

#### 双通道模型的优势

通过将卷积网络和KAN网络的输出通过可学习参数加权结合，我们的双通道模型能够有效地整合局部和全局信息。这种设计不仅提高了模型的预测准确性，还增强了模型的可解释性。具体而言，卷积网络提供的局部特征聚合能够帮助模型快速识别直接关联，而KAN网络则通过全局特征的捕捉，确保模型能够考虑到更广泛的上下文信息。

双通道模型的设计还克服了以往单一模型在处理复杂图数据时的局限性，特别是在节点特征维度较高且节点间关系复杂的情况下。通过这种综合性的特征学习方法，我们的模型在节点关联预测任务中展现出更优的性能和更强的鲁棒性。

双通道网络模型的设计不仅解决了传统模型在特征提取上的不足，还通过局部与全局信息的有效结合，推动了节点关联预测效果。


---
## Dual-Channel Fusion and Final Prediction√
